{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wardla2/Data-Science-Portfolio/blob/main/Project_2/2510_2_LWard_Project_2_Housing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting Home Sale Prices: A Data-Driven Approach to Real Estate Valuation"
      ],
      "metadata": {
        "id": "cJG_e1vK2NMI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Definition\n"
      ],
      "metadata": {
        "id": "Ugnt7mjT2Pyt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This goal of this project is to help a real estate company accurately predict house sale prices based on property features such as size, location, and age. The business goal is to improve pricing strategies and decision-making for buyers and sellers. This is a supervised regression problem, where the target variable is the numeric sale price. The  model will attempt minimize Root Mean Squared Percentage Error (RMSPE) to ensure accurate predictions."
      ],
      "metadata": {
        "id": "DJB41zc-2q-w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Collection/Sources\n"
      ],
      "metadata": {
        "id": "jaq46wHS2Uh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data set contains information from the\n",
        "Assessor's Office used in computing assessed values for individual\n",
        "residential properties sold from 2006 to 2010.\n",
        "It is hosted in an AWS S3 bucket.\n",
        "https://www.google.com/url?q=https%3A%2F%2Fddc-datascience.s3.amazonaws.com%2FProjects%2FProject.2-Housing%2FData%2FHousing.Data.csv"
      ],
      "metadata": {
        "id": "5zBHA_LvbBsu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## File Paths"
      ],
      "metadata": {
        "id": "jcwLaiHdb4Nv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = \"https://ddc-datascience.s3.amazonaws.com/Projects/Project.2-Housing/Data/Housing.Data.csv\"\n"
      ],
      "metadata": {
        "id": "6DcnuR8Gb_QM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Additional imports\n",
        "\n",
        "import numpy as np         # Numerical operations\n",
        "import matplotlib.pyplot as plt    # Basic plotting\n",
        "import seaborn as sns              # Statistical plots\n",
        "import plotly.express as px        # Interactive plots\n",
        "\n",
        "from sklearn.model_selection import train_test_split       # Splitting data\n",
        "from sklearn.preprocessing import RobustScaler           # Feature scaling\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder            # Categorical encoding\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, r2_score   # Basic metrics\n"
      ],
      "metadata": {
        "id": "ZHkIYQVXWFEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "housing_df = pd.read_csv(url)\n",
        "housing_df\n"
      ],
      "metadata": {
        "id": "PffpZYxkTNQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning\n"
      ],
      "metadata": {
        "id": "kvTak8Ka2db2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Backup 1"
      ],
      "metadata": {
        "id": "C-4twfSxXxJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial backup copy of the data frame\n",
        "\n",
        "housing_df_bak1 = housing_df.copy()\n",
        "housing_df_bak1\n"
      ],
      "metadata": {
        "id": "k4Q6cbo42paj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing_df.info()\n"
      ],
      "metadata": {
        "id": "vGHha7dUYXRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing_df.describe()\n"
      ],
      "metadata": {
        "id": "66t5E5s-YhW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing_df.shape\n"
      ],
      "metadata": {
        "id": "bgR1sM9GYmvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing_df.size\n"
      ],
      "metadata": {
        "id": "qxgV5W9pYpvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing_df.head(5)\n"
      ],
      "metadata": {
        "id": "wDp3edr6YtxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing_df.tail(5)\n"
      ],
      "metadata": {
        "id": "JykJs8sVYyHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View null values\n",
        "\n",
        "housing_df.isna().sum()\n"
      ],
      "metadata": {
        "id": "cIYB8UMtY3XB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of distinct elements in rows\n",
        "\n",
        "housing_df.nunique().sort_values(ascending = False).head(20)\n"
      ],
      "metadata": {
        "id": "TPlDslRNZJ_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing_df.nunique().sort_values(ascending = False).tail(20)\n"
      ],
      "metadata": {
        "id": "omr1hzrnaGIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if there are null series\n",
        "\n",
        "housing_df.isnull().all()\n"
      ],
      "metadata": {
        "id": "CUuMuw8aapeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count nulls per column, sort descending\n",
        "\n",
        "column_nulls = housing_df.isnull().sum().sort_values(ascending=False)\n",
        "\n",
        "column_nulls\n"
      ],
      "metadata": {
        "id": "q4Rhb9pQdCtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_nulls[column_nulls > 0]\n"
      ],
      "metadata": {
        "id": "Ihu8ndg5d-WE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop data series that have null values > ~ 1/3\n",
        "\n",
        "drop = column_nulls[column_nulls > 880]\n",
        "drop\n"
      ],
      "metadata": {
        "id": "XZ73ZL_8gq3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unecessary and low-value data series\n",
        "\n",
        "housing_df.drop(columns=list(drop.index) + ['PID'], inplace=True)\n"
      ],
      "metadata": {
        "id": "tWTg0kHpfxmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check remaining number of columns\n",
        "housing_df.info()\n"
      ],
      "metadata": {
        "id": "qf_EGNkdFqis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for rows with null values in the 'SalePrice' field\n",
        "\n",
        "housing_df['SalePrice'].isna()\n"
      ],
      "metadata": {
        "id": "Wze3g6dafEiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for rows with >= 10% null values\n",
        "\n",
        "row_nulls = housing_df[housing_df.isnull().sum(axis=1) >= 7]\n",
        "row_nulls"
      ],
      "metadata": {
        "id": "PiWr6nljorj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with >= 7 missing values\n",
        "\n",
        "housing_df.drop(index=row_nulls.index, inplace=True)\n"
      ],
      "metadata": {
        "id": "im2z1_sPrv-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing_df.info()\n"
      ],
      "metadata": {
        "id": "rzwJXEaMsRB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing_df.isna().sum().sort_values(ascending=False).head(20)\n"
      ],
      "metadata": {
        "id": "vOBSTWhYtndh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make backup 2"
      ],
      "metadata": {
        "id": "X218m2ADtNEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make backup 2\n",
        "\n",
        "housing_df_lowNaN = housing_df.copy()\n",
        "housing_df_lowNaN\n"
      ],
      "metadata": {
        "id": "0ePyzz0HtIlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Keep only numeric series"
      ],
      "metadata": {
        "id": "VGshD4Pm-_Ji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify numeric series\n",
        "\n",
        "housing_numeric_series_df = housing_df_lowNaN.select_dtypes(include='number')\n",
        "housing_numeric_series_df\n"
      ],
      "metadata": {
        "id": "L4VMhfbw-4qY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Establish drop thresholds for series with significant zero values\n",
        "zero_threshold = 0.55   # Drop if 55%+ values are zero\n",
        "\n",
        "# Establish drop thresholds for series with low abs correlation with SalesPrice\n",
        "corr_threshold = 0.45 #Drop if abs(correlation with SalesPrice) =<45%\n",
        "\n",
        "# Calculate percent of zeros\n",
        "zero_fraction = (housing_numeric_series_df == 0).sum() / len(housing_numeric_series_df)\n",
        "\n",
        "# Correlation with target\n",
        "correlations = housing_numeric_series_df.corr()['SalePrice'].abs()\n",
        "\n",
        "# Identify series to drop\n",
        "drop_numeric_series = zero_fraction[(zero_fraction > zero_threshold) & (correlations < corr_threshold)].index.tolist()\n",
        "drop_numeric_series\n"
      ],
      "metadata": {
        "id": "dSzMzI8hnhPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop series that have significant zero values and and low abs correlation with SalesPrice\n",
        "\n",
        "housing_numeric_series_df.drop(columns=drop_numeric_series , inplace=True)\n",
        "housing_numeric_series_df\n"
      ],
      "metadata": {
        "id": "5vTtQ282Ir5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Look for numeric series correlated with each other & != target\n",
        "\n",
        "# Compute feature correlation matrix\n",
        "corr_matrix = housing_numeric_series_df.corr().abs()\n",
        "\n",
        "# Get features' correlation with target\n",
        "target_col = 'SalePrice'\n",
        "\n",
        "# Make a list of correlated feature pairs\n",
        "corr_threshold = 0.75\n",
        "\n",
        "corr_pairs = [\n",
        "  (col1, col2 , corr_matrix.loc[col1, col2])\n",
        "  for col1 in corr_matrix.columns\n",
        "  for col2 in corr_matrix.columns\n",
        "  if col1 != col2\n",
        "  and col1 != target_col\n",
        "  and col2 != target_col\n",
        "  and corr_matrix.loc[col1, col2] > corr_threshold\n",
        "]\n",
        "\n",
        "corr_pairs\n"
      ],
      "metadata": {
        "id": "aClpJvbmM-0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Get correlation of all features with SalePrice\n",
        "target_corr = corr_matrix[target_col]\n",
        "target_corr\n"
      ],
      "metadata": {
        "id": "Ie6ir5y9UDBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop features less correlated with SalePrice\n",
        "\n",
        "drop_features = set()\n",
        "\n",
        "for col1, col2, corr_val in corr_pairs:\n",
        "    if col1 in drop_features or col2 in drop_features:\n",
        "        continue  # skip already selected for drop to avoid overlapping pairs\n",
        "    if target_corr[col1] < target_corr[col2]:\n",
        "        drop_features.add(col1)\n",
        "    else:\n",
        "        drop_features.add(col2)\n",
        "\n",
        "# Then drop them from the DataFrame\n",
        "housing_numeric_series_df.drop(columns=drop_features, inplace=True)\n"
      ],
      "metadata": {
        "id": "DuzRhG9WPY58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing_numeric_series_df.info()\n"
      ],
      "metadata": {
        "id": "y81h6JRWU9Ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if numeric dtypes series are continuous, nominal, or ordinal categorical in data dictionary:\n",
        "# https://ddc-datascience.s3.amazonaws.com/Projects/Project.2-Housing/Housing%20-%20Data%20Documentation.pdf\n",
        "drop_noncontinuous = ['MS SubClass','Overall Qual','Overall Cond','Mo Sold']\n",
        "\n",
        "# Drop non-continuous series\n",
        "housing_numeric_series_df.drop(columns = drop_noncontinuous, inplace=True)\n",
        "housing_numeric_series_df\n"
      ],
      "metadata": {
        "id": "zD8bFKW1WjJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing_numeric_series_df.info()\n"
      ],
      "metadata": {
        "id": "jcl7QDYwjqZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Strip SalePrice (target var) and Yr Sold (possibly a numeric categorical) from data frame\n",
        "\n",
        "housing_numeric_series_df.drop(columns=['Yr Sold'], inplace=True)\n",
        "housing_numeric_series_df.info()\n"
      ],
      "metadata": {
        "id": "3XiA8dC165xR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encode 'object' categorical series"
      ],
      "metadata": {
        "id": "Qo9cS1uTxeVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# These are the numeric categoricals identified in the numeric datatype series\n",
        "\n",
        "numeric_categoricals = ['MS SubClass','Mo Sold','Yr Sold']"
      ],
      "metadata": {
        "id": "U98T9gccku1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select datatype 'object' series from DataFrame\n",
        "categorical_obj = housing_df_lowNaN.select_dtypes(include='object')\n",
        "\n",
        "\n",
        "# Build a summary DataFrame for 'object' data\n",
        "obj_summary = pd.DataFrame({\n",
        "    'column': categorical_obj.columns,\n",
        "    'n_unique': [housing_df_lowNaN[col].nunique() for col in categorical_obj.columns]\n",
        "})\n",
        "\n",
        "# Sort summary DataFrame by number of unique values\n",
        "obj_summary.sort_values(by='n_unique', ascending=True, inplace=True)\n",
        "\n",
        "# Show\n",
        "obj_summary.reset_index(drop=True, inplace=True)\n",
        "obj_summary\n"
      ],
      "metadata": {
        "id": "PFPmVf-n_zcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Put categorical object columns in a list\n",
        "\n",
        "categorical_obj = housing_df_lowNaN.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "# Print unique values for each\n",
        "for col in categorical_obj:\n",
        "    print(f\"{col} ({housing_df_lowNaN[col].nunique()} unique values):\")\n",
        "    print(housing_df_lowNaN[col].unique())\n",
        "    print('-' * 15)\n"
      ],
      "metadata": {
        "id": "xgZ0zhH4Gfs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if numeric dtypes series are nominal or ordinal categorical in data dictionary:\n",
        "# https://ddc-datascience.s3.amazonaws.com/Projects/Project.2-Housing/Housing%20-%20Data%20Documentation.pdf\n",
        "\n",
        "# Make ordinal series list\n",
        "\n",
        "obj_ordinal_series = ['Overall Qual','Overall Cond','Land Slope','Lot Shape','Utilities','Exter Qual',\n",
        "                  'Exter Cond','Bsmt Qual','Bsmt Cond','Bsmt Exposure','BsmtFin Type 1','BsmtFin Type 2',\n",
        "                  'Heating QC','Electrical','Kitchen Qual','Garage Finish','Garage Qual','Garage Cond','Paved Drive']\n",
        "obj_ordinal_series\n"
      ],
      "metadata": {
        "id": "jPqPxg7ggaV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make nominal series list\n",
        "\n",
        "obj_nominal_series = obj_nominal_series = [col for col in categorical_obj if col not in obj_ordinal_series]\n",
        "obj_nominal_series\n"
      ],
      "metadata": {
        "id": "1MMzoTEIMz2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plan for adding 'object' categorical series to prediction models\n",
        "\n",
        "* One-hot encode nominal series and correlate with target series;\n",
        "* Drop nominal series uncorrelated with target;\n",
        "* Encode ord series as ordered numbers;\n",
        "* Drop ord series uncorrelated with target;\n",
        "* Concat numeric / nom / ord categorical series --> make all features DataFrame for train-test sets and model prediction\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EQbP4DIJjWY6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis\n"
      ],
      "metadata": {
        "id": "Gvh5r9Zs2fkc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Independence of features & correlation"
      ],
      "metadata": {
        "id": "HQ4wviy9vReh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Backup 3"
      ],
      "metadata": {
        "id": "p1g_QJ7lvdrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make simple var backup for numeric series EDA\n",
        "\n",
        "housing_numeric_series_df_bak = housing_numeric_series_df.copy()\n",
        "housing_df_eda1 = housing_numeric_series_df.copy()\n",
        "housing_df_eda1\n"
      ],
      "metadata": {
        "id": "2Efloab12ouN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for skewness of numeric data series prior to scaling\n",
        "\n",
        "skewed_vars = [\n",
        "    col for col in housing_df_eda1.select_dtypes(include='number').columns\n",
        "    if abs(housing_df_eda1[col].skew()) > 0.05\n",
        "]\n",
        "skewed_vars"
      ],
      "metadata": {
        "id": "SVsv48VR9lcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visually inspect numeric data series using KDE\n",
        "\n",
        "# Select only numeric columns (exclude 'SalePrice')\n",
        "numeric_cols = housing_df_eda1.select_dtypes(include='number').columns.drop('SalePrice', errors='ignore')\n",
        "\n",
        "for col in numeric_cols:\n",
        "    plt.figure(figsize=(5, 3))\n",
        "    sns.histplot(data=housing_df_eda1, x=col, kde=True, bins=30, color='pink')\n",
        "    plt.title(f'Distribution of {col}')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "BiuM1b_m_iO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processing\n",
        "\n"
      ],
      "metadata": {
        "id": "Ij_fgEbh2hVk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scale numeric series"
      ],
      "metadata": {
        "id": "yO0k_asRBB93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set X (features) and y (target) values\n",
        "\n",
        "X = housing_numeric_series_df.drop(columns='SalePrice')\n",
        "y = housing_numeric_series_df['SalePrice']\n",
        "X, y\n"
      ],
      "metadata": {
        "id": "FbdLva6bBBl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set train/test split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=0\n",
        ")\n",
        "X_train, X_test, y_train, y_test\n"
      ],
      "metadata": {
        "id": "Z1w1e2SH2oOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the scaler on training data only\n",
        "\n",
        "scaler = RobustScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_train_scaled_array = X_train_scaled\n",
        "X_train_scaled_array"
      ],
      "metadata": {
        "id": "zGlssNxWFIDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the fitted scaler to transform test data\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_test_scaled_array = X_test_scaled\n",
        "X_test_scaled_array\n"
      ],
      "metadata": {
        "id": "Ro6VHELoGgLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make features_to_plot as list of column names\n",
        "features_to_plot = X.columns\n",
        "\n",
        "# Copy unscaled data\n",
        "X_unscaled = X.copy()\n",
        "\n",
        "# Convert scaled array back to DataFrame\n",
        "X_scaled = pd.DataFrame(X_train_scaled_array, columns=features_to_plot)\n",
        "\n",
        "# Plot\n",
        "for col in features_to_plot:\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    sns.kdeplot(X_unscaled[col], label='Unscaled', fill=True, linewidth=2)\n",
        "    sns.kdeplot(X_scaled[col], label='Robust Scaled', fill=True, linewidth=2)\n",
        "    plt.title(f\"Distribution of '{col}' Before vs After Scaling\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "eNF4B36KTC1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compare RMSPE for models applied to numeric series"
      ],
      "metadata": {
        "id": "TbJby_6imgXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make RMSPE scorer\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "def rmspe(y_true, y_pred):\n",
        "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
        "\n",
        "rmspe_scorer = make_scorer(rmspe, greater_is_better=False)\n"
      ],
      "metadata": {
        "id": "k6a2sq2Umoi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute NaN values and make recommended models\n",
        "\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "\n",
        "# Pipelines with imputer + scaler + model\n",
        "models = {\n",
        "    'Linear': make_pipeline(SimpleImputer(strategy='median'), RobustScaler(), LinearRegression()),\n",
        "    'Ridge': make_pipeline(SimpleImputer(strategy='median'), RobustScaler(), Ridge(alpha=1.0)),\n",
        "    'Lasso': make_pipeline(SimpleImputer(strategy='median'), RobustScaler(), Lasso(alpha=0.01, max_iter=10000))\n",
        "}\n"
      ],
      "metadata": {
        "id": "n3ztvh4S1Zwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-validation\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    scores = cross_val_score(model, X_train, y_train, scoring=rmspe_scorer, cv=5)\n",
        "    results[name] = -scores.mean()\n",
        "\n",
        "# Results\n",
        "for model_name, score in results.items():\n",
        "  print(f\"{model_name}: Mean RMSPE (CV=5) = {score:.5f}\")\n"
      ],
      "metadata": {
        "id": "AJYQjeIv17_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Isolate Ridge model\n",
        "\n",
        "ridge_model = make_pipeline(\n",
        "    SimpleImputer(strategy='median'),\n",
        "    RobustScaler(),\n",
        "    Ridge(alpha=1.0)\n",
        ")\n",
        "\n",
        "ridge_model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "feorM5V-PDOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect predictive features\n",
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "# Access the trained Ridge model inside the pipeline\n",
        "ridge_regressor = ridge_model.named_steps['ridge']\n",
        "\n",
        "# Extract the coefficients\n",
        "ridge_coefs = pd.Series(ridge_regressor.coef_, index=X_train.columns)\n",
        "\n",
        "# Sort by absolute value\n",
        "ridge_coefs_sorted = ridge_coefs.reindex(ridge_coefs.abs().sort_values(ascending=False).index)\n",
        "\n",
        "# Show top features\n",
        "print(ridge_coefs_sorted.head(15))\n"
      ],
      "metadata": {
        "id": "F4IXDLh3OSpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot predictive features\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "ridge_coefs_sorted.head(15).plot(kind='barh', color='steelblue')\n",
        "plt.gca().invert_yaxis()  # largest at top\n",
        "plt.title(\"Top 15 Most Predictive Features (Ridge Regression)\")\n",
        "plt.xlabel(\"Coefficient Magnitude\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xRsyl7tCOeyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test best prediction model (lowest Mean RMSPE)"
      ],
      "metadata": {
        "id": "neoc8Cc93f-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test prediction model\n",
        "\n",
        "# Choose best model from cross-validation\n",
        "final_model = models['Ridge']\n",
        "\n",
        "# Fit on the entire training set\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data (scaling & imputation handled inside pipeline)\n",
        "y_pred = final_model.predict(X_test)\n",
        "y_pred #predicted sales prices\n"
      ],
      "metadata": {
        "id": "IHmU26-72NzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Visualization/Communication of Results\n"
      ],
      "metadata": {
        "id": "gjDTKyc12jR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare actual and predicted sales prices\n",
        "\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Actual': y_test.values,\n",
        "    'Predicted': y_pred\n",
        "})\n",
        "\n",
        "print(comparison_df.head(15))\n"
      ],
      "metadata": {
        "id": "IlNH7PFy2k9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get mean RMSPE for test data set\n",
        "\n",
        "def rmspe(y_true, y_pred):\n",
        "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
        "\n",
        "test_rmspe = rmspe(y_test, y_pred)\n",
        "print(f\"Test data mean RMSPE (CV=5): {test_rmspe:.5f}\")\n"
      ],
      "metadata": {
        "id": "4jEJKwWb46kD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot actual vs predicted prices for test data set\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.5)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')  # prediction line\n",
        "plt.xlabel('Actual Sale Price')\n",
        "plt.ylabel('Predicted Sale Price')\n",
        "plt.title('Actual vs Predicted Sale Prices')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WjL74aHU5H9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "# Compute residuals\n",
        "residuals = y_test - y_pred\n",
        "\n",
        "# Q-Q plot\n",
        "plt.figure(figsize=(8,6))\n",
        "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
        "plt.title(\"Q-Q Plot of Residuals\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3Ee7Nb-u-N9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Residuals and fitted values\n",
        "\n",
        "residuals = y_test - y_pred\n",
        "fitted = y_pred\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(fitted, residuals, alpha=0.6)\n",
        "plt.axhline(0, color='red', linestyle='--', linewidth=2)\n",
        "plt.xlabel(\"Fitted Values (Predicted Sale Price)\")\n",
        "plt.ylabel(\"Residuals (Actual - Predicted)\")\n",
        "plt.title(\"Residuals vs. Fitted Values\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8xTe6YRR-Qe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplot of residuals vs. year sold\n",
        "\n",
        "x = housing_df_lowNaN['Yr Sold']\n",
        "\n",
        "sns.boxplot(x=x, y=residuals)\n",
        "plt.axhline(0, color='red', linestyle='--')\n",
        "plt.title(\"Residuals by Year Sold\")\n",
        "plt.xlabel(\"Year Sold\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "flLIarsEJwN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Residuals vs sales index - shows feature indepedence\n",
        "\n",
        "res = residuals\n",
        "\n",
        "plt.figure(figsize = (14,10))\n",
        "plt.scatter(range(len(res)), res)\n",
        "plt.plot(range(len(res)), res)\n",
        "plt.title(\"Residuals by Sales Index\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.hlines(0, min(range(len(res))), max(range(len(res))), colors = 'red', linestyles = 'dashed') ;\n"
      ],
      "metadata": {
        "id": "e9mwgBMq-2u6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}